{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PanoEvJ/my-MLE-11/blob/week10-assignment/assignments/week-10-nlp/nb/hate_speech_detector_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvQ6ov4HzBKX"
      },
      "source": [
        "<p align = \"center\" draggable=‚Äùfalse‚Äù ><img src=\"https://user-images.githubusercontent.com/37101144/161836199-fdb0219d-0361-4988-bf26-48b0fad160a3.png\" \n",
        "     width=\"200px\"\n",
        "     height=\"auto\"/>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9V9ctujXqHSO"
      },
      "source": [
        "# Hate Speech Detector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIZSzVH_qHSO"
      },
      "source": [
        "Today you are a machine learning engineer, a member of the Birdwatch at Twitter. \n",
        "\n",
        "The objective of this task is to detect hate speech in tweets. For the sake of simplicity, a tweet contains hate speech if it has a racist or sexist sentiment associated with it. In other words, we need to classify racist or sexist tweets from other tweets.\n",
        "\n",
        "A labelled dataset of 31,962 tweets (late 2017 to early 2018) is provided in the form of a compressed csv file with each line storing a tweet id, its label, and the tweet. Label '1' denotes the tweet is racist/sexist while label '0' denotes the tweet is not racist/sexist.\n",
        "\n",
        "We will first approach the problem in a traditional approach: clean the raw text using simple regex (regular expression), extract features, build a naive Bayes models to classify tweets; then we build a deep learning model and explain our deep learning model with LIME."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUnzuOszqHSP"
      },
      "source": [
        "## üìö Learning Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8Z3BzFrqHSP"
      },
      "source": [
        "By the end of this lesson, you will be able to:\n",
        "\n",
        "- Understand the basic concepts in natural language processing (NLP)\n",
        "- Perform basic NLP tasks on text, e.g., tweets\n",
        "- Build a naive Bayes classifier to detect hate speech \n",
        "- Build a bidirectional long short-term memory (BiLSTM) to detect hate speech\n",
        "- Visualize embeddings with Tensorboard embedding projector\n",
        "- Explain models with LIME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KdYEyU4zNGU"
      },
      "source": [
        "# Task I: Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESJru9iiqHSQ"
      },
      "source": [
        "1. Install dependencies.\n",
        "\n",
        "    Most modules are pre-installed in Colab, however, we need to update `gensim` to its recent version and install `lime`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzQ5eaRK6-GB",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a70047d-4b3e-4218-a51b-3848c18d26f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m275.7/275.7 KB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -U -q gensim==4.2.0 lime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfT65m3lyxZ_"
      },
      "source": [
        "2. Connect Colab to your local Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FOuYW07fyzbP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b7bc08c-f9c5-4a1d-d9a0-ebf8606fc904"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ws9_nx44qHSZ"
      },
      "source": [
        "3. Use `pandas.read_csv` to load the tweets in `tweets.csv.gz` and save the `pd.DataFrame` into `raw`. Make sure the path points to where the data is located in your Google Drive. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOc7kHGny04E"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "dataset = '/content/drive/My Drive/fourthbrain/tweets.csv.gz'  # YOUR CODE HERE\n",
        "raw = pd.read_csv(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y85-t5JzzihL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "576a91d7-0dd9-4328-8df0-3337f74ec15d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 31962 entries, 0 to 31961\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   id      31962 non-null  int64 \n",
            " 1   label   31962 non-null  int64 \n",
            " 2   tweet   31962 non-null  object\n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 749.2+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(raw.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvsKB7cmqHSa"
      },
      "source": [
        "4. Sample 5 random tweets from the dataset for each label and display `label` and `tweet` columns. \n",
        "Hint: one option is to use `sample()` followed by `groupby`. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw.groupby('label')[['label','tweet']].sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "-L5SJe7chIOm",
        "outputId": "140c3973-4d1e-41b0-b3ec-799eacb274dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       label                                              tweet\n",
              "29859      0  5 night time mistakes that will keep ...  #tip...\n",
              "30553      0  happy father's day dad! #abc7chicago   #father...\n",
              "11816      0   @user i am thankful for saturdays. #thankful ...\n",
              "5281       0   @user @user you do have a point. i know what ...\n",
              "18705      0    father sings happy bihday to daughter strand...\n",
              "6224       1  @user this sums up why i voted for #brexit; no...\n",
              "7021       1  and how do jews plan on doing the work of god ...\n",
              "28500      1  @user #feminismiscancer #feminismisterrorism #...\n",
              "25667      1  @user paul beloy:  is still an issue at varyin...\n",
              "12336      1  @user care about #cjreform? follow me: i cover..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e545b0d0-6861-458d-94ed-8a0ec82fe043\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>29859</th>\n",
              "      <td>0</td>\n",
              "      <td>5 night time mistakes that will keep ...  #tip...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30553</th>\n",
              "      <td>0</td>\n",
              "      <td>happy father's day dad! #abc7chicago   #father...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11816</th>\n",
              "      <td>0</td>\n",
              "      <td>@user i am thankful for saturdays. #thankful ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5281</th>\n",
              "      <td>0</td>\n",
              "      <td>@user @user you do have a point. i know what ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18705</th>\n",
              "      <td>0</td>\n",
              "      <td>father sings happy bihday to daughter strand...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6224</th>\n",
              "      <td>1</td>\n",
              "      <td>@user this sums up why i voted for #brexit; no...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7021</th>\n",
              "      <td>1</td>\n",
              "      <td>and how do jews plan on doing the work of god ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28500</th>\n",
              "      <td>1</td>\n",
              "      <td>@user #feminismiscancer #feminismisterrorism #...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25667</th>\n",
              "      <td>1</td>\n",
              "      <td>@user paul beloy:  is still an issue at varyin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12336</th>\n",
              "      <td>1</td>\n",
              "      <td>@user care about #cjreform? follow me: i cover...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e545b0d0-6861-458d-94ed-8a0ec82fe043')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e545b0d0-6861-458d-94ed-8a0ec82fe043 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e545b0d0-6861-458d-94ed-8a0ec82fe043');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "application/vnd.google.colaboratory.module+javascript": "\n      import \"https://ssl.gstatic.com/colaboratory/data_table/fb998edc550c7947/data_table.js\";\n\n      window.createDataTable({\n        data: [[{\n            'v': 29859,\n            'f': \"29859\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n\"5 night time mistakes that will keep ...  #tips #life   |  \"],\n [{\n            'v': 30553,\n            'f': \"30553\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n\"happy father's day dad! #abc7chicago   #fathers #day #celebration \"],\n [{\n            'v': 11816,\n            'f': \"11816\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n\" @user i am thankful for saturdays. #thankful #positive     \"],\n [{\n            'v': 5281,\n            'f': \"5281\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n\" @user @user you do have a point. i know what i would've done and it's what you've said! but i'm trained to do it too. #s\\u00e2\\u0080\\u00a6\"],\n [{\n            'v': 18705,\n            'f': \"18705\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n\"  father sings happy bihday to daughter stranded in iran: richard ratcliffe, from west hampstead, lond... \"],\n [{\n            'v': 6224,\n            'f': \"6224\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        },\n\"@user this sums up why i voted for #brexit; not  or #littleenglander syndrome but sovereignty and democracy   \"],\n [{\n            'v': 7021,\n            'f': \"7021\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        },\n\"and how do jews plan on doing the work of god without god?  matthew 1:23 \\\"...and they will call him immanuel\\u00e2\\u0080\\u009d (whic\\u00e2\\u0080\\u00a6 \"],\n [{\n            'v': 28500,\n            'f': \"28500\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        },\n\"@user #feminismiscancer #feminismisterrorism #feminismmuktbharat why  #malevote is ignored  @user\"],\n [{\n            'v': 25667,\n            'f': \"25667\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        },\n\"@user paul beloy:  is still an issue at varying levels in belgian football  @user \"],\n [{\n            'v': 12336,\n            'f': \"12336\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        },\n\"@user care about #cjreform? follow me: i cover #deathpenalty, #juvenilejustice, #bailreform, #prosecutorialmisconduct, \\u00e2\\u0080\\u00a6\"]],\n        columns: [[\"number\", \"index\"], [\"number\", \"label\"], [\"string\", \"tweet\"]],\n        columnOptions: [{\"width\": \"1px\", \"className\": \"index_column\"}],\n        rowsPerPage: 25,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: undefined,\n      });\n    "
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6C7suQv4z7xE",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "d2c33ff9-a7ae-4cbd-f276-f1a5c4360118"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       label                                              tweet\n",
              "20028      0   @user   saturday @user  @user @user @user din...\n",
              "9956       0   √¢¬Ü¬ù #united states eia crude oil stocks chang...\n",
              "4165       0  my mama has been one kind of cancer free for f...\n",
              "31787      0  have a beautiful saturday! √¢¬ù¬§√Ø¬∏¬è . . . . day ...\n",
              "9360       0   fathersdayquotes #the #best  #fathers #day #q..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bf70a632-98fc-4e5c-836c-89bbace50cf8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20028</th>\n",
              "      <td>0</td>\n",
              "      <td>@user   saturday @user  @user @user @user din...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9956</th>\n",
              "      <td>0</td>\n",
              "      <td>√¢¬Ü¬ù #united states eia crude oil stocks chang...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4165</th>\n",
              "      <td>0</td>\n",
              "      <td>my mama has been one kind of cancer free for f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31787</th>\n",
              "      <td>0</td>\n",
              "      <td>have a beautiful saturday! √¢¬ù¬§√Ø¬∏¬è . . . . day ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9360</th>\n",
              "      <td>0</td>\n",
              "      <td>fathersdayquotes #the #best  #fathers #day #q...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bf70a632-98fc-4e5c-836c-89bbace50cf8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bf70a632-98fc-4e5c-836c-89bbace50cf8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bf70a632-98fc-4e5c-836c-89bbace50cf8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "application/vnd.google.colaboratory.module+javascript": "\n      import \"https://ssl.gstatic.com/colaboratory/data_table/fb998edc550c7947/data_table.js\";\n\n      window.createDataTable({\n        data: [[{\n            'v': 20028,\n            'f': \"20028\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n\" @user   saturday @user  @user @user @user dinavalenz  @user kazzeymusic &lt;== #listen to\\u00e2\\u0080\\u00a6\"],\n [{\n            'v': 9956,\n            'f': \"9956\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n\" \\u00e2\\u0086\\u009d #united states eia crude oil stocks change registered at -0.933m above expectations (-2.26m) in june 10   #\\u00e2\\u0080\\u00a6\"],\n [{\n            'v': 4165,\n            'f': \"4165\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n\"my mama has been one kind of cancer free for five years and is officially released by one of her oncologists!   making #1000gifts\"],\n [{\n            'v': 31787,\n            'f': \"31787\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n\"have a beautiful saturday! \\u00e2\\u009d\\u00a4\\u00ef\\u00b8\\u008f . . . . day 162 #366photos2016 #saturday   #weekend\\u00e2\\u0080\\u00a6 \"],\n [{\n            'v': 9360,\n            'f': \"9360\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n\" fathersdayquotes #the #best  #fathers #day #quotes #| #bihday buy things abo\\u00e2\\u0080\\u00a6  \"]],\n        columns: [[\"number\", \"index\"], [\"number\", \"label\"], [\"string\", \"tweet\"]],\n        columnOptions: [{\"width\": \"1px\", \"className\": \"index_column\"}],\n        rowsPerPage: 25,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: undefined,\n      });\n    "
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Colab includes an extension that renders pandas dataframes into interactive displays that can be filtered, sorted, and explored dynamically.\n",
        "from google.colab import data_table\n",
        "data_table.enable_dataframe_formatter() \n",
        "\n",
        "# YOUR CODE HERE\n",
        "raw[['label','tweet']].sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTX1dJ79qHSb"
      },
      "source": [
        "5. The tweets are in English and all words should be already in lowercase. \n",
        "Now calculate the number of characters in each tweet and assign the values to a new column `len_tweet` in `raw`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZpPnJ7hzoUY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "6dcbd0cc-613e-4649-eacd-84b95e5e013f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          id  label                                              tweet  \\\n",
              "5299    5300      0   @user #sketching a #moose  had a lot of #fun ...   \n",
              "27946  27947      0  #model   i love u take with u all the time in ...   \n",
              "4478    4479      0                                  fathers day guys    \n",
              "6176    6177      0  #vehicle   gorilla simulator: you need to do t...   \n",
              "26929  26930      0            we're delighted you're making the trip    \n",
              "\n",
              "       len_tweet  \n",
              "5299         103  \n",
              "27946         86  \n",
              "4478          19  \n",
              "6176         109  \n",
              "26929         39  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fbd8956e-d6f2-4892-8745-6157013707e4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>len_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5299</th>\n",
              "      <td>5300</td>\n",
              "      <td>0</td>\n",
              "      <td>@user #sketching a #moose  had a lot of #fun ...</td>\n",
              "      <td>103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27946</th>\n",
              "      <td>27947</td>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4478</th>\n",
              "      <td>4479</td>\n",
              "      <td>0</td>\n",
              "      <td>fathers day guys</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6176</th>\n",
              "      <td>6177</td>\n",
              "      <td>0</td>\n",
              "      <td>#vehicle   gorilla simulator: you need to do t...</td>\n",
              "      <td>109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26929</th>\n",
              "      <td>26930</td>\n",
              "      <td>0</td>\n",
              "      <td>we're delighted you're making the trip</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fbd8956e-d6f2-4892-8745-6157013707e4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fbd8956e-d6f2-4892-8745-6157013707e4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fbd8956e-d6f2-4892-8745-6157013707e4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "application/vnd.google.colaboratory.module+javascript": "\n      import \"https://ssl.gstatic.com/colaboratory/data_table/fb998edc550c7947/data_table.js\";\n\n      window.createDataTable({\n        data: [[{\n            'v': 5299,\n            'f': \"5299\",\n        },\n{\n            'v': 5300,\n            'f': \"5300\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n\" @user #sketching a #moose  had a lot of #fun with this one. #ilovedrawing #animals #a makes me   \\u00f0\\u009f\\u0098\\u0083 \",\n{\n            'v': 103,\n            'f': \"103\",\n        }],\n [{\n            'v': 27946,\n            'f': \"27946\",\n        },\n{\n            'v': 27947,\n            'f': \"27947\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n\"#model   i love u take with u all the time in ur\\u00f0\\u009f\\u0093\\u00b1!!! \\u00f0\\u009f\\u0098\\u0099\\u00f0\\u009f\\u0098\\u008e\\u00f0\\u009f\\u0091\\u0084\\u00f0\\u009f\\u0091\\u0085\\u00f0\\u009f\\u0092\\u00a6\\u00f0\\u009f\\u0092\\u00a6\\u00f0\\u009f\\u0092\\u00a6  \",\n{\n            'v': 86,\n            'f': \"86\",\n        }],\n [{\n            'v': 4478,\n            'f': \"4478\",\n        },\n{\n            'v': 4479,\n            'f': \"4479\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n\"  fathers day guys \",\n{\n            'v': 19,\n            'f': \"19\",\n        }],\n [{\n            'v': 6176,\n            'f': \"6176\",\n        },\n{\n            'v': 6177,\n            'f': \"6177\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n\"#vehicle   gorilla simulator: you need to do to adapt to the environment. the need to tear the city. materia \",\n{\n            'v': 109,\n            'f': \"109\",\n        }],\n [{\n            'v': 26929,\n            'f': \"26929\",\n        },\n{\n            'v': 26930,\n            'f': \"26930\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n\"we're delighted you're making the trip \",\n{\n            'v': 39,\n            'f': \"39\",\n        }]],\n        columns: [[\"number\", \"index\"], [\"number\", \"id\"], [\"number\", \"label\"], [\"string\", \"tweet\"], [\"number\", \"len_tweet\"]],\n        columnOptions: [{\"width\": \"1px\", \"className\": \"index_column\"}],\n        rowsPerPage: 25,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: undefined,\n      });\n    "
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "len_tweet = []\n",
        "for tweet in raw['tweet']:\n",
        "  len_tweet.append(len(tweet))\n",
        "raw['len_tweet'] = len_tweet\n",
        "raw.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cs6Xn-YtqHSc"
      },
      "source": [
        "6. What are the summary statistics of `len_tweet` for each label? \n",
        "Hint: use `groupby` and `describe`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ClwQM1Zezwq6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "outputId": "dfe10427-1d40-4629-8860-5f544b518fb2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         count  mean   std   min   25%   50%    75%    max\n",
              "label                                                     \n",
              "0      29720.0  84.3  29.6  11.0  62.0  88.0  107.0  274.0\n",
              "1       2242.0  90.2  27.4  12.0  69.0  96.0  111.0  152.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-999b919c-09ce-4cb8-a7bb-d7698b733424\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>29720.0</td>\n",
              "      <td>84.3</td>\n",
              "      <td>29.6</td>\n",
              "      <td>11.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>107.0</td>\n",
              "      <td>274.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2242.0</td>\n",
              "      <td>90.2</td>\n",
              "      <td>27.4</td>\n",
              "      <td>12.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>111.0</td>\n",
              "      <td>152.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-999b919c-09ce-4cb8-a7bb-d7698b733424')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-999b919c-09ce-4cb8-a7bb-d7698b733424 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-999b919c-09ce-4cb8-a7bb-d7698b733424');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "application/vnd.google.colaboratory.module+javascript": "\n      import \"https://ssl.gstatic.com/colaboratory/data_table/fb998edc550c7947/data_table.js\";\n\n      window.createDataTable({\n        data: [[{\n            'v': 0,\n            'f': \"0\",\n        },\n{\n            'v': 29720.0,\n            'f': \"29720.0\",\n        },\n{\n            'v': 84.32863391655451,\n            'f': \"84.32863391655451\",\n        },\n{\n            'v': 29.566483817431827,\n            'f': \"29.566483817431827\",\n        },\n{\n            'v': 11.0,\n            'f': \"11.0\",\n        },\n{\n            'v': 62.0,\n            'f': \"62.0\",\n        },\n{\n            'v': 88.0,\n            'f': \"88.0\",\n        },\n{\n            'v': 107.0,\n            'f': \"107.0\",\n        },\n{\n            'v': 274.0,\n            'f': \"274.0\",\n        }],\n [{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': 2242.0,\n            'f': \"2242.0\",\n        },\n{\n            'v': 90.18777876895629,\n            'f': \"90.18777876895629\",\n        },\n{\n            'v': 27.375501683643677,\n            'f': \"27.375501683643677\",\n        },\n{\n            'v': 12.0,\n            'f': \"12.0\",\n        },\n{\n            'v': 69.0,\n            'f': \"69.0\",\n        },\n{\n            'v': 96.0,\n            'f': \"96.0\",\n        },\n{\n            'v': 111.0,\n            'f': \"111.0\",\n        },\n{\n            'v': 152.0,\n            'f': \"152.0\",\n        }]],\n        columns: [[\"number\", \"label\"], [\"number\", \"count\"], [\"number\", \"mean\"], [\"number\", \"std\"], [\"number\", \"min\"], [\"number\", \"25%\"], [\"number\", \"50%\"], [\"number\", \"75%\"], [\"number\", \"max\"]],\n        columnOptions: [{\"width\": \"1px\", \"className\": \"index_column\"}],\n        rowsPerPage: 25,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: undefined,\n      });\n    "
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "from pandas.core import describe\n",
        "pd.set_option(\"display.precision\", 1)\n",
        "\n",
        "# YOUR CODE HERE\n",
        "raw.groupby('label')['len_tweet'].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJpa1yzaqHSc"
      },
      "source": [
        "Note we have an imbalanced dataset: the ratio of non-hate speech to hate speech is roughly 13:1. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-1PGVKaqHSc"
      },
      "source": [
        "7. Clean the tweets. \n",
        "\n",
        "    We use `re` to perform basic text manipulations. \n",
        "    Specically, remove anonymized user handle, remove numbers and special characters except hashtags."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZ5dN1CEz1Y4"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_5sDDyHqHSd"
      },
      "source": [
        "8. Remove user handles from the text in `tweet`, or anything directly following the symbols `@`, and save the resulting tweets to a new column `tidy_tweet` in `raw`. \n",
        "    \n",
        "    Hint: you can use `re.sub` on individual text and [`apply`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html) a simple lambda function for the series `raw['tweet']`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5fQIuPm0h9A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "feb81cad-190b-4626-e0b8-71f086ed60ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          id  label                                              tweet  \\\n",
              "790      791      1  @user and you keep telling that only aryans ar...   \n",
              "21928  21929      0                           @user what makes you  ?    \n",
              "25642  25643      0   √¢¬Ü¬ù #nzd/usd extends rbnz-led rally, hits fre...   \n",
              "20436  20437      0  i'm on a mission to ride all of the animals!  ...   \n",
              "22552  22553      0  the color of a human skin matters a lot to the...   \n",
              "\n",
              "       len_tweet                                         tidy_tweet  \n",
              "790          109    and you keep telling that only aryans are al...  \n",
              "21928         25                                 what makes you  ?   \n",
              "25642        101   √¢¬Ü¬ù #nzd/usd extends rbnz-led rally, hits fre...  \n",
              "20436         91  i'm on a mission to ride all of the animals!  ...  \n",
              "22552         88  the color of a human skin matters a lot to the...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fcec899a-53a2-4d83-b820-eff85002d0d5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>len_tweet</th>\n",
              "      <th>tidy_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>790</th>\n",
              "      <td>791</td>\n",
              "      <td>1</td>\n",
              "      <td>@user and you keep telling that only aryans ar...</td>\n",
              "      <td>109</td>\n",
              "      <td>and you keep telling that only aryans are al...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21928</th>\n",
              "      <td>21929</td>\n",
              "      <td>0</td>\n",
              "      <td>@user what makes you  ?</td>\n",
              "      <td>25</td>\n",
              "      <td>what makes you  ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25642</th>\n",
              "      <td>25643</td>\n",
              "      <td>0</td>\n",
              "      <td>√¢¬Ü¬ù #nzd/usd extends rbnz-led rally, hits fre...</td>\n",
              "      <td>101</td>\n",
              "      <td>√¢¬Ü¬ù #nzd/usd extends rbnz-led rally, hits fre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20436</th>\n",
              "      <td>20437</td>\n",
              "      <td>0</td>\n",
              "      <td>i'm on a mission to ride all of the animals!  ...</td>\n",
              "      <td>91</td>\n",
              "      <td>i'm on a mission to ride all of the animals!  ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22552</th>\n",
              "      <td>22553</td>\n",
              "      <td>0</td>\n",
              "      <td>the color of a human skin matters a lot to the...</td>\n",
              "      <td>88</td>\n",
              "      <td>the color of a human skin matters a lot to the...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fcec899a-53a2-4d83-b820-eff85002d0d5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fcec899a-53a2-4d83-b820-eff85002d0d5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fcec899a-53a2-4d83-b820-eff85002d0d5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "application/vnd.google.colaboratory.module+javascript": "\n      import \"https://ssl.gstatic.com/colaboratory/data_table/fb998edc550c7947/data_table.js\";\n\n      window.createDataTable({\n        data: [[{\n            'v': 790,\n            'f': \"790\",\n        },\n{\n            'v': 791,\n            'f': \"791\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        },\n\"@user and you keep telling that only aryans are allowed to rape women! you're just a  troll! #eod @user @user\",\n{\n            'v': 109,\n            'f': \"109\",\n        },\n\"  and you keep telling that only aryans are allowed to rape women! you're just a  troll! #eod    \"],\n [{\n            'v': 21928,\n            'f': \"21928\",\n        },\n{\n            'v': 21929,\n            'f': \"21929\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n\" @user what makes you  ? \",\n{\n            'v': 25,\n            'f': \"25\",\n        },\n\"   what makes you  ? \"],\n [{\n            'v': 25642,\n            'f': \"25642\",\n        },\n{\n            'v': 25643,\n            'f': \"25643\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n\" \\u00e2\\u0086\\u009d #nzd/usd extends rbnz-led rally, hits fresh 1-year high near 0.7150   #blog #silver #gold #forex\",\n{\n            'v': 101,\n            'f': \"101\",\n        },\n\" \\u00e2\\u0086\\u009d #nzd/usd extends rbnz-led rally, hits fresh 1-year high near 0.7150   #blog #silver #gold #forex\"],\n [{\n            'v': 20436,\n            'f': \"20436\",\n        },\n{\n            'v': 20437,\n            'f': \"20437\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n\"i'm on a mission to ride all of the animals!   #teamchanlv #vegas #lasvegas #funtimes  \\u00e2\\u0080\\u00a6 \",\n{\n            'v': 91,\n            'f': \"91\",\n        },\n\"i'm on a mission to ride all of the animals!   #teamchanlv #vegas #lasvegas #funtimes  \\u00e2\\u0080\\u00a6 \"],\n [{\n            'v': 22552,\n            'f': \"22552\",\n        },\n{\n            'v': 22553,\n            'f': \"22553\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n\"the color of a human skin matters a lot to the system when it comes to judgement call.  \",\n{\n            'v': 88,\n            'f': \"88\",\n        },\n\"the color of a human skin matters a lot to the system when it comes to judgement call.  \"]],\n        columns: [[\"number\", \"index\"], [\"number\", \"id\"], [\"number\", \"label\"], [\"string\", \"tweet\"], [\"number\", \"len_tweet\"], [\"string\", \"tidy_tweet\"]],\n        columnOptions: [{\"width\": \"1px\", \"className\": \"index_column\"}],\n        rowsPerPage: 25,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: undefined,\n      });\n    "
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "raw['tidy_tweet'] = raw['tweet'].map(lambda x: re.sub(r\"@[\\w]+\",' ',x)) # YOUR CODE HERE\n",
        "raw.sample(5, random_state=203)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45_NFIzUqHSd"
      },
      "source": [
        "9. Remove non-alphabetic characters yet keep symbols `#` from `tidy_tweet` and save the result in `tidy_tweet`. \n",
        "In other words, keep all 26 letters and `#`.\n",
        "\n",
        "    Note: in some applications, punctuations, emojis, or whether the word is in all caps can be of use. \n",
        "    You shall decide whether to extract such features for the application and perform error analysis to gain insight. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OiPc6R6q0rtH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "bde267fd-0610-4c42-9a23-fa82b8334ee9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          id  label                                              tweet  \\\n",
              "790      791      1  @user and you keep telling that only aryans ar...   \n",
              "21928  21929      0                           @user what makes you  ?    \n",
              "25642  25643      0   √¢¬Ü¬ù #nzd/usd extends rbnz-led rally, hits fre...   \n",
              "20436  20437      0  i'm on a mission to ride all of the animals!  ...   \n",
              "22552  22553      0  the color of a human skin matters a lot to the...   \n",
              "\n",
              "       len_tweet                                         tidy_tweet  \n",
              "790          109    and you keep telling that only aryans are al...  \n",
              "21928         25                                 what makes you      \n",
              "25642        101       #nzd usd extends rbnz led rally  hits fre...  \n",
              "20436         91  i m on a mission to ride all of the animals   ...  \n",
              "22552         88  the color of a human skin matters a lot to the...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-73ba2968-63d1-4df9-86a8-ad72e9bbf56f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>len_tweet</th>\n",
              "      <th>tidy_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>790</th>\n",
              "      <td>791</td>\n",
              "      <td>1</td>\n",
              "      <td>@user and you keep telling that only aryans ar...</td>\n",
              "      <td>109</td>\n",
              "      <td>and you keep telling that only aryans are al...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21928</th>\n",
              "      <td>21929</td>\n",
              "      <td>0</td>\n",
              "      <td>@user what makes you  ?</td>\n",
              "      <td>25</td>\n",
              "      <td>what makes you</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25642</th>\n",
              "      <td>25643</td>\n",
              "      <td>0</td>\n",
              "      <td>√¢¬Ü¬ù #nzd/usd extends rbnz-led rally, hits fre...</td>\n",
              "      <td>101</td>\n",
              "      <td>#nzd usd extends rbnz led rally  hits fre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20436</th>\n",
              "      <td>20437</td>\n",
              "      <td>0</td>\n",
              "      <td>i'm on a mission to ride all of the animals!  ...</td>\n",
              "      <td>91</td>\n",
              "      <td>i m on a mission to ride all of the animals   ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22552</th>\n",
              "      <td>22553</td>\n",
              "      <td>0</td>\n",
              "      <td>the color of a human skin matters a lot to the...</td>\n",
              "      <td>88</td>\n",
              "      <td>the color of a human skin matters a lot to the...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-73ba2968-63d1-4df9-86a8-ad72e9bbf56f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-73ba2968-63d1-4df9-86a8-ad72e9bbf56f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-73ba2968-63d1-4df9-86a8-ad72e9bbf56f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "application/vnd.google.colaboratory.module+javascript": "\n      import \"https://ssl.gstatic.com/colaboratory/data_table/fb998edc550c7947/data_table.js\";\n\n      window.createDataTable({\n        data: [[{\n            'v': 790,\n            'f': \"790\",\n        },\n{\n            'v': 791,\n            'f': \"791\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        },\n\"@user and you keep telling that only aryans are allowed to rape women! you're just a  troll! #eod @user @user\",\n{\n            'v': 109,\n            'f': \"109\",\n        },\n\"  and you keep telling that only aryans are allowed to rape women  you re just a  troll  #eod    \"],\n [{\n            'v': 21928,\n            'f': \"21928\",\n        },\n{\n            'v': 21929,\n            'f': \"21929\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n\" @user what makes you  ? \",\n{\n            'v': 25,\n            'f': \"25\",\n        },\n\"   what makes you    \"],\n [{\n            'v': 25642,\n            'f': \"25642\",\n        },\n{\n            'v': 25643,\n            'f': \"25643\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n\" \\u00e2\\u0086\\u009d #nzd/usd extends rbnz-led rally, hits fresh 1-year high near 0.7150   #blog #silver #gold #forex\",\n{\n            'v': 101,\n            'f': \"101\",\n        },\n\"     #nzd usd extends rbnz led rally  hits fresh   year high near          #blog #silver #gold #forex\"],\n [{\n            'v': 20436,\n            'f': \"20436\",\n        },\n{\n            'v': 20437,\n            'f': \"20437\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n\"i'm on a mission to ride all of the animals!   #teamchanlv #vegas #lasvegas #funtimes  \\u00e2\\u0080\\u00a6 \",\n{\n            'v': 91,\n            'f': \"91\",\n        },\n\"i m on a mission to ride all of the animals    #teamchanlv #vegas #lasvegas #funtimes      \"],\n [{\n            'v': 22552,\n            'f': \"22552\",\n        },\n{\n            'v': 22553,\n            'f': \"22553\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n\"the color of a human skin matters a lot to the system when it comes to judgement call.  \",\n{\n            'v': 88,\n            'f': \"88\",\n        },\n\"the color of a human skin matters a lot to the system when it comes to judgement call   \"]],\n        columns: [[\"number\", \"index\"], [\"number\", \"id\"], [\"number\", \"label\"], [\"string\", \"tweet\"], [\"number\", \"len_tweet\"], [\"string\", \"tidy_tweet\"]],\n        columnOptions: [{\"width\": \"1px\", \"className\": \"index_column\"}],\n        rowsPerPage: 25,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: undefined,\n      });\n    "
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "raw['tidy_tweet'] = raw['tidy_tweet'].map(lambda x: re.sub('[^a-zA-Z#]', ' ',x)) # YOUR CODE HERE\n",
        "raw.sample(5, random_state=203)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcClbClQIrRV"
      },
      "source": [
        "10. Remove words that is shorter than 4 characters from the processed tweets.\n",
        "\n",
        "    For example, \n",
        "      \n",
        "    `i m on a mission to ride all of the animals #teamchanlv #vegas #lasvegas #funtimes`\n",
        "      \n",
        "    will be reduced to \n",
        "      \n",
        "    `mission ride animals #teamchanlv #vegas #lasvegas #funtimes`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KTx-49cdInP3"
      },
      "outputs": [],
      "source": [
        "raw['tidy_tweet'] = # YOUR CODE HERE\n",
        "raw.sample(5, random_state=203)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5tzGFhXqHSd"
      },
      "source": [
        "11. Remove stopwords and perform text normalization. \n",
        "    \n",
        "    We will use `stopwords` collection and `SnowballStemmer` in `nltk` for this task. Before doing so, we need to tokenize the tweets. \n",
        "    Tokens are individual terms or words, and tokenization is simply to split a string of text into tokens. \n",
        "    You can use [`str.split()`](https://docs.python.org/3/library/stdtypes.html#str.split) on individual text and [`apply`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html) a simple lambda function for the series `raw['tidy_tweet']` and save the result into `tokenized_tweet`. \n",
        "    \n",
        "    Check out some methods for the built-in type `str` [here](https://docs.python.org/3/library/stdtypes.html#string-methods)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLxQQG8600Hs"
      },
      "outputs": [],
      "source": [
        "tokenized_tweet = # YOUR CODE HERE\n",
        "tokenized_tweet.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHtedqavqHSe"
      },
      "source": [
        "12. Extract stop words and remove them from the tokens.\n",
        "\n",
        "    Note: depending on the task / industry, it is highly recommended that one curate custom stop words. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wG6tMYE9qHSe"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEUuHQ_VeT01"
      },
      "outputs": [],
      "source": [
        "tokenized_tweet = # YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4NlUGjqCqHSe"
      },
      "outputs": [],
      "source": [
        "assert any(word in tokenized_tweet for word in stop_words) == False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iQM37ChqHSe"
      },
      "source": [
        "13. Create a new instance of a language specific [`SnowballStemmer`](https://www.nltk.org/api/nltk.stem.snowball.html), set the `language` to be \"english\"; see [how to](https://www.nltk.org/howto/stem.html). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "deglx5x_04Bw"
      },
      "outputs": [],
      "source": [
        "from nltk.stem.snowball import SnowballStemmer\n",
        "stemmer = # YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_BhAT652eT02"
      },
      "outputs": [],
      "source": [
        "tokenized_tweet = tokenized_tweet.apply(lambda x: [stemmer.stem(i) for i in x]) \n",
        "tokenized_tweet.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvMfXkyiqHSe"
      },
      "source": [
        "14. Lastly, let's stitch these tokens in `tokenized_tweet` back together and save them in `raw['tidy_tweet']`. \n",
        "Use [`str.join()`](https://docs.python.org/3/library/stdtypes.html#str.join) and `apply`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxJgsMjL1Bp-"
      },
      "outputs": [],
      "source": [
        "raw['tidy_tweet'] = # YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ui0kvijA1SKS"
      },
      "source": [
        "# Task 2. Wordcloud and Hashtag"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xgyq4Qj0qHSg"
      },
      "source": [
        "In this task, we want to gain a general idea of what the common words were and how hashtags were used in tweets. \n",
        "We will create wordclouds and extract the top hashtags used in each label. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcNrDDXUqHSg"
      },
      "source": [
        "1. Before doing so, out of caution of possible data leakage, split the `raw['tidy_tweet']` into training and test datasets in a stratified fashion, set the test size at .25 and random state as 42.\n",
        "    \n",
        "    Save the results into `X_train`, `X_test`, `y_train`, and `y_test`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwoflQr71QhH"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    raw['tidy_tweet'], raw.label, \n",
        "    test_size=0.25, random_state=42, stratify=raw.label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QKFflId1XYb"
      },
      "outputs": [],
      "source": [
        "assert X_train.shape == y_train.shape == (23971, )\n",
        "assert X_test.shape == y_test.shape == (7991,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1JaWVklqHSg"
      },
      "source": [
        "2. A word cloud is a cluster of words depicted in different sizes. \n",
        "The bigger the word appears, the more often it appears in the given text. \n",
        "It can offer an easy visual presentation to reveal the theme of a topic. \n",
        "\n",
        "    Function `plot_wordcloud` is provided to plot 50 most frequent words from the given text in the shape of twitter's logo. \n",
        "    You may need to replace the image path accordingly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UByekRZz1rxT"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "def plot_wordcloud(text:str) -> None:\n",
        "    '''\n",
        "    Plot a wordcloud of top 50 words from the input text\n",
        "    masked by twitter logo\n",
        "    '''\n",
        "    mask = np.array(Image.open('/content/drive/My Drive/img/twitter-mask.png')) # REPLACE w/ YOUR FILE PATH\n",
        "    wordcloud = WordCloud( \n",
        "        background_color='white', \n",
        "        random_state=42,\n",
        "        max_words=50, \n",
        "        max_font_size=80, \n",
        "        mask = mask).generate(text)\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bK-Eqb1qHSh"
      },
      "source": [
        "3. Visualize the wordcloud. \n",
        "\n",
        "    The function expects one long string. \n",
        "    Stitch all tidy tweets from training set and save the single string to `all_words`, then visualize the wordcloud for all the words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EnDDuy7R2Bb5"
      },
      "outputs": [],
      "source": [
        "all_words = # YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ee6LQ9dE2TYi"
      },
      "outputs": [],
      "source": [
        "plot_wordcloud(all_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luL-uZdHqHSh"
      },
      "source": [
        "4. Visualize the wordcloud just for the text from the tweets identified as hate speech. \n",
        "\n",
        "    Similarly, you need to stitch all the tidy tweets in training set that were identified as hate speech. \n",
        "    Save the long string to `negative_words`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gp9fXlr2pik"
      },
      "outputs": [],
      "source": [
        "negative_words = # YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmtJ41t22uhR"
      },
      "outputs": [],
      "source": [
        "plot_wordcloud(negative_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0B4y2c0qHSh"
      },
      "source": [
        "5. Hashtag is a feature for tweets and we would like to inspect if hashtags provide information for our classification task. \n",
        "\n",
        "    Function `hashtag_extract` is provided to extract hastags from an iterable (list or series) and return the hashtags in a list. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqtqY7a422_e"
      },
      "outputs": [],
      "source": [
        "def hashtag_extract(x) -> list:\n",
        "    \"\"\"\n",
        "    extract hastags from an iterable (list or series) and \n",
        "    return the hashtags in a list.\n",
        "    \"\"\"\n",
        "    hashtags = []\n",
        "    # Loop over the words in the tweet\n",
        "    for i in x:\n",
        "        ht = re.findall(r\"#(\\w+)\", i)\n",
        "        hashtags.append(ht)\n",
        "    return hashtags"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nU3Zu-flqHSh"
      },
      "source": [
        "6. Extract hashtags from non-hate speech tweets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVXhRL7m264-"
      },
      "outputs": [],
      "source": [
        "HT_regular = # YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vp1TyoOL3OoM"
      },
      "outputs": [],
      "source": [
        "assert type(HT_regular) == list\n",
        "assert type(HT_regular[0]) == list # nested list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AmW0K8HqHSh"
      },
      "source": [
        "7. Now extract hashtags from hate speech tweets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLaYv03728h5"
      },
      "outputs": [],
      "source": [
        "HT_negative = # YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cowz9OnGqHSi"
      },
      "source": [
        "8. Both `HT_regular` and `HT_negative` are nested lists, so use the following trick to unnest both lists."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQnGQJ2n3F1X"
      },
      "outputs": [],
      "source": [
        "HT_regular = sum(HT_regular,[])\n",
        "HT_negative = sum(HT_negative,[])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDYOiVR83H1c"
      },
      "outputs": [],
      "source": [
        "assert type(HT_regular) == type(HT_negative) == list\n",
        "assert type(HT_regular[0]) == type(HT_negative[0]) == str"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zR7o3Cp7qHSi"
      },
      "source": [
        "9. Complete the function `top_hashtags` below to take a list of hashtags and return the top `n` hashtag keyword and its frequncy. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDatTFKT3cjp"
      },
      "outputs": [],
      "source": [
        "from typing import List, Tuple\n",
        "from collections import Counter\n",
        "def top_hashtags(hashtags:List[str], n=10) -> List[Tuple[str, int]]:\n",
        "    ''' Function to return the top n hashtags '''\n",
        "    # YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_delVSfeT09"
      },
      "source": [
        "1. Apply the function to the hashtag lists from the non-hate speech tweets and the hate speech tweets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gG84iMvE3m78"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BHAjo7Y3pYO"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjJbs5SsqHSi"
      },
      "source": [
        "10. DISCUSS: are these hashtags making sense? should we include them as features or should we strip the # before tokenizing (that is, treat \"#love\" the same as \"love\")? why and why not?\n",
        "          #YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEYAGVIl37vK"
      },
      "source": [
        "# Task 3. Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7ekNaI9qHSj"
      },
      "source": [
        "Note that almost all the machine learning related Python modules expect numerical presentation of data; thus we need to transform our text first.\n",
        "We will experiment with bag of words, tf-idf, and word2vec.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKTmxB0BqHSj"
      },
      "source": [
        "1. Convert the collection of text documents to a matrix of token counts.\n",
        "\n",
        "    Check the [official documentation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html). \n",
        "    \n",
        "    Create an instance of `CountVectorizer` named `bow_vectorizer`, set `max_features` to be `MAX_FEATURES`.\n",
        "    Learn the vocabulary dictionary and return document-term matrix and save it to `bow_train`. Use `.fit_transform`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNb93rk3392m"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "MAX_FEATURES = 1000\n",
        "\n",
        "\n",
        "bow_vectorizer = # YOUR CODE HERE\n",
        "bow_train = # YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZd0m7px4OEZ"
      },
      "outputs": [],
      "source": [
        "assert bow_train.shape == (X_train.shape[0], MAX_FEATURES)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gW16ek1qHSj"
      },
      "source": [
        "2. Print the first three rows from `bow_train`. Hint: `.toarray()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pYsQFElmqHSj"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lY2VSoMg48kb",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from scipy.sparse.csr import csr_matrix\n",
        "assert type(bow_train) == csr_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQdQrhVNqHSj"
      },
      "source": [
        "3. Similarly, convert the collection of text documents to a matrix of TF-IDF features.\n",
        "    \n",
        "    Create an instance of [`TfidfVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer) named `tfidf_vectorizer`, set `max_features` to be `MAX_FEATURES`.\n",
        "\n",
        "    Learn the vocabulary and idf, return document-term matrix and save it to `tfidf_train`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijW78I3v4Y81"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDUa96KO4bmT"
      },
      "outputs": [],
      "source": [
        "tfidf_vectorizer = # YOUR CODE HERE\n",
        "tfidf_train = "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTrhLbMi4fjg"
      },
      "outputs": [],
      "source": [
        "assert type(tfidf_train) == csr_matrix\n",
        "assert tfidf_train.shape == bow_train.shape == (X_train.shape[0], MAX_FEATURES)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OSGoE73Avaj"
      },
      "source": [
        "4. Extract word embeddings using Word2Vec. \n",
        "We will use [`gensim`](https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html) for this task. \n",
        "    \n",
        "    The Word2Vec model takes either a list of lists of tokens or an iterable that streams the sentences directly from disk/network. \n",
        "    Here, we tokenize the tidy tweets in `X_train` and save the list (`pd.series`) of lists of tokens to `tokenized_tweet`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sadI5JU257TF"
      },
      "outputs": [],
      "source": [
        "tokenized_tweet = # YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MK1E2oM36Apt"
      },
      "outputs": [],
      "source": [
        "assert tokenized_tweet.shape == X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQ__p8hn6E5r"
      },
      "outputs": [],
      "source": [
        "tokenized_tweet.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBeFwgakqHSk"
      },
      "source": [
        "5. Import `Word2Vec` from `gensim.models`; see [doc](https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec). \n",
        "\n",
        "    Create a skip-gram `Word2Vec` instance named `w2v` that learns on the `tokenized_tweet`, with `vector_size` set at `MAX_FEATURES`, and other parameters are provided. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vgYpd2kq6LW0"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfPufOPJ6MFl"
      },
      "outputs": [],
      "source": [
        "w2v = Word2Vec(\n",
        "        # YOUR CODE HERE\n",
        "        # YOUR CODE HERE\n",
        "        window=5, min_count=2, sg = 1, \n",
        "        hs = 0, negative = 10,  workers= 2, \n",
        "        seed = 34)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpSomU5qqHSk"
      },
      "source": [
        "6. Train the skip-gram model, set the epochs at 20."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eyMxunhc7jAm"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIGnBtKvqHSk"
      },
      "source": [
        "7. Let's see how the model performs. \n",
        "Specify a word and print out the 10 most similar words from the our tweets in the training set. \n",
        "Use [`most_similar`](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.KeyedVectors.most_similar). \n",
        "Hint: print the type of `w2v` and `w2v.wv`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sy9r-1Uz7sXl"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THzz40pI8cii"
      },
      "source": [
        "8. Discuss: how does w2v calculate the similarities? \n",
        "\n",
        "  YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpUeqahqqHSl"
      },
      "source": [
        "9. Discuss: do you think Word2Vec is supervised or unsupervised ML technique?\n",
        "\n",
        "    YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kDDUHKTqHSl"
      },
      "source": [
        "10. Engineer features. \n",
        "\n",
        "    For each tweet, we calculate the average of embeddings (function `word_vector`) and then apply it to every tidy tweet in `X_train` (use function `tokens_to_array`).\n",
        "    Both functions are provided, inspect the code and save the features in `w2v_train`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NudS0OF28b_d"
      },
      "outputs": [],
      "source": [
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "\n",
        "def word_vector(tokens:list, size:int, keyed_vec:KeyedVectors= w2v.wv):\n",
        "    vec = np.zeros(size).reshape((1, size))\n",
        "    count = 0\n",
        "    for word in tokens:\n",
        "        try:\n",
        "            vec += keyed_vec[word].reshape((1, size))\n",
        "            count += 1\n",
        "        except KeyError: \n",
        "            # handling the case where the token is not in vocabulary        \n",
        "            continue\n",
        "    if count != 0:\n",
        "        vec /= count\n",
        "    return vec\n",
        "\n",
        "def tokens_to_array(tokens:list, size:int, keyed_vec:KeyedVectors= w2v.wv):\n",
        "    array = np.zeros((len(tokens), size))\n",
        "    for i in range(len(tokens)):\n",
        "        array[i,:] = word_vector(tokens.iloc[i], size, keyed_vec=keyed_vec)\n",
        "    return array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vea6FT7V8yuR"
      },
      "outputs": [],
      "source": [
        "w2v_train = # YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UV5XtAk09iZl"
      },
      "outputs": [],
      "source": [
        "assert w2v_train.shape == (X_train.shape[0], MAX_FEATURES)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhzWKjs_9o55"
      },
      "source": [
        "11. Prepare the test data before modeling for each approach:\n",
        "\n",
        "\n",
        "  - extract features from `X_test` using the bag of words approach; use `bow_vectorizer`\n",
        "  - extract features from `X_test` using the tf-idf approach; use `tfidf_vectorizer`\n",
        "  - extract features from `X_test` using Word2Vec embeddings; you need to first tokenized the tidy tweets in `X_test`, then convert the tokens to array of shape `(X_test.shape[0], MAX_FEATURES)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iv5j92GP9nyC"
      },
      "outputs": [],
      "source": [
        "bow_test = # YOUR CODE HERE\n",
        "tfidf_test = # YOUR CODE HERE\n",
        "\n",
        "tokenized_tweet_test = # YOUR CODE HERE\n",
        "w2v_test = # YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJw-KwNu9_l6"
      },
      "outputs": [],
      "source": [
        "assert bow_test.shape == tfidf_test.shape == w2v_test.shape == (X_test.shape[0], MAX_FEATURES)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zHJBHsC3w7J"
      },
      "source": [
        "# Task 4. Naive Bayes classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bN3pJcOI3_xs"
      },
      "source": [
        "In this task, you will build a [naive Bayes](https://sebastianraschka.com/Articles/2014_naive_bayes_1.html) (here's another [ref](https://www.inf.ed.ac.uk/teaching/courses/inf2b/learnnotes/inf2b-learn07-notes-nup.pdf)), classifiers to identify the hate speech tweets using different sets of features from the last task, and evaluate their performances. \n",
        "\n",
        "In the era of deep learning, naive Bayes is useful due to its simplicity and reasonable performance, especially if there is not much training data available. A common interview question is \"Why is naive Bayes naive?\". \n",
        "\n",
        "We will use multi-variate Bernoulli naive Bayes [`BernoulliNB`](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html); try other flavors of [naive Bayes](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.naive_bayes) if time permits. Code is pretty straightforward. \n",
        "\n",
        "1. Import `BernoulliNB` for modeling and `classification_report` for reporting performance. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwaj5Ksd3rk8"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lp8jYLY_qHSm"
      },
      "source": [
        "2. Create an instance of  `BernoulliNB` named `BNBmodel`. \n",
        "\n",
        "    We can use it for all three feature sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9NtOCqv3wRK"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKuGCGdfqHSm"
      },
      "source": [
        "3. Train the multi-variate Bernoulli naive Bayes using bag of words features and print the performance report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJjuMZspahLB"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE (train the model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNzjV0mUqHSm"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE (report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntqO9Ic1qHSm"
      },
      "source": [
        "4. Similarly, train the model using tf-idf features and print the performance report. \n",
        "\n",
        "    Is the performance expected? Why or why not?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8X0OXMVt-he0"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUi0SFfFqHSm"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJQu2WZyqHSm"
      },
      "source": [
        "5. Finally, train the model using Word2Vec embeddings and report the performance. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h69fbpcvbHs8"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fm1hTdBf_qJd"
      },
      "source": [
        "6. Discuss the differences in performace using tf-idf vs skim-gram embeddings. \n",
        "\n",
        "    YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XdbHGM8qHSm"
      },
      "source": [
        "7. Examine a few tweets where the model(s) failed. \n",
        "What other features would you include in the next iteration?\n",
        "\n",
        "    YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wmj2oYYlAG9t"
      },
      "source": [
        "# Task 5. Bidirectional LSTM "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivL3qYLXALKo"
      },
      "source": [
        "In this task, you will build a bidirectional LSTM (BiLSTM) model to detect tweets identified as hate speech, and visualize the embedding layer using Tensorboard projector. \n",
        "\n",
        "Why BiLSTM? LSTM, at its core, preserves information from inputs that has already passed through it using the hidden state. Unidirectional LSTM only preserves information of the past because the only inputs it has seen are from the past. BiLSTMs run inputs in both ways, one from past to future and one from future to past and show very good results as they can understand context better [ref](https://stackoverflow.com/questions/43035827/whats-the-difference-between-a-bidirectional-lstm-and-an-lstm)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bFkC-qRqHSn"
      },
      "source": [
        "1. Tokenizing and padding. \n",
        "    \n",
        "    As LSTM expects every sentence to be of the same length, in addition to [`Tokenizer`](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer) with a given number of vocabulary `VOCAB_SIZE`, we need to [pad](https://www.tensorflow.org/api_docs/python/tf/keras/utils/pad_sequences) shorter tweets with 0s until the length is `MAX_LEN` and truncate longer tweets to be exact `MAX_LEN` long. \n",
        "    \n",
        "   Function `tokenize_pad_sequences` is provided except that you need to supply correct `num_words` and `filters`; do NOT filter `#`. \n",
        "   \n",
        "   We feed the processed `tidy_tweet` to `tokenize_pad_sequences`, but one can perform the preprocessing steps in `Tokenizer` and apply it directly on the raw tweets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iC1Q6k3j-5qW"
      },
      "outputs": [],
      "source": [
        "VOCAB_SIZE = 25000  \n",
        "MAX_LEN = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1LG6ZQ7CKKi"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def tokenize_pad_sequences(text):\n",
        "    '''\n",
        "    tokenize the input text into sequences of integers and then\n",
        "    pad each sequence to the same length\n",
        "    '''\n",
        "    # Text tokenization\n",
        "    tokenizer = Tokenizer(\n",
        "        num_words=# YOUR CODE HERE\n",
        "        filters=# YOUR CODE HERE\n",
        "        lower=True, split=' ', oov_token='oov')\n",
        "    tokenizer.fit_on_texts(text)\n",
        "    # Transforms text to a sequence of integers\n",
        "    X = tokenizer.texts_to_sequences(text)\n",
        "    # Pad sequences to the same length\n",
        "    X = pad_sequences(X, padding='post', maxlen=MAX_LEN)\n",
        "\n",
        "    return X, tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MhnJ9nxCNca"
      },
      "outputs": [],
      "source": [
        "print('Before Tokenization & Padding \\n', raw['tidy_tweet'][0])\n",
        "X, tokenizer = tokenize_pad_sequences(raw['tidy_tweet'])\n",
        "print('After Tokenization & Padding \\n', X[0])\n",
        "y = raw['label'].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhG33jJeqHSn"
      },
      "source": [
        "2. Let's split `X` into training and testing datasets, save 25% for testing. \n",
        "Then split training dataset into training and validation datasets, with 20% for validation. \n",
        "Set both `random_state` to be 42. \n",
        "Stratify both splits. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PIdaTdBKCP-2"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    # YOUR CODE HERE\n",
        "    )\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    # YOUR CODE HERE\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2G5PMwGCcxI"
      },
      "outputs": [],
      "source": [
        "print('Train Set ->', X_train.shape, y_train.shape)\n",
        "print('Validation Set ->', X_val.shape, y_val.shape)\n",
        "print('Test Set ->', X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmZ2Y9gzqHSn"
      },
      "source": [
        "3. Now build a sequential model:\n",
        "\n",
        "    - an embedding layer\n",
        "    - a bidirectional LSTM with 32 units and set `return_sequences=True` in LSTM\n",
        "    - a global average pooling operation for temporal data\n",
        "    - a dropout layer with 20% rate\n",
        "    - a dense layer of 32 units and set the activation function to be ReLu\n",
        "    - a dense layer of 1 unit and set the proper activation function for classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIHXdzW7Che7",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "# YOUR CODE HERE (layer imports)\n",
        "\n",
        "EMBEDDING_DIM = 16   \n",
        "model = Sequential([\n",
        "    # YOUR CODE HERE\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpioKB2AC6aH"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjzENFrAqHSo"
      },
      "source": [
        "4. Compile the model. \n",
        "\n",
        "    Fill in a proper loss function and use adam as the optimizer. \n",
        "    For metrics, include precision and recall in the metrics, in addition to accuracy. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RuhniNmJC2AR"
      },
      "outputs": [],
      "source": [
        "from keras.metrics import Precision, Recall\n",
        "model.compile(\n",
        "    loss=# YOUR CODE HERE\n",
        "    optimizer='adam', \n",
        "    metrics=# YOUR CODE HERE]\n",
        "    ) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiXFn0OJqHSo"
      },
      "source": [
        "5. Train the model for 10 epochs on training dataset with a  validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1pd8qpIC_BL"
      },
      "outputs": [],
      "source": [
        "EPOCHS=10\n",
        "BATCH_SIZE = 32\n",
        "history = model.fit(X_train, y_train,\n",
        "                    validation_data=# YOUR CODE HERE\n",
        "                    batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USmxE6M1qHSo"
      },
      "source": [
        "6. Function `plot_graphs` is provided below to visualize how the performance of model progresses as a function of epoch. \n",
        "\n",
        "    Visualize accuracy and loss. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3IuUmpODCz1"
      },
      "outputs": [],
      "source": [
        "def plot_graphs(history, metric):\n",
        "  fig, ax = plt.subplots()\n",
        "  plt.plot(history.history[metric])\n",
        "  plt.plot(history.history['val_'+metric], '')\n",
        "  ax.set_xticks(range(EPOCHS))\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(metric)\n",
        "  plt.legend([metric, 'val_'+metric])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXsbpHwQDNbf"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emrqqQacDPFL"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGE0rR41qHSo"
      },
      "source": [
        "7. The model starts to overfit after a couple of epochs. \n",
        "Consider using [early stopping](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping) to stop training when a monitored metric has stopped improving. \n",
        "\n",
        "  What can we do to tame overfitting?\n",
        "\n",
        "    YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJj8v7mdqHSo"
      },
      "source": [
        "8. Print the classification report of the model on test dataset. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AdobNLdZDT81"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgfrk6iRqHSo"
      },
      "source": [
        "9. Discuss: how does the BiLSTM model improve the classification over naive Bayes? \n",
        "\n",
        "    YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQ7B-g_fEWYe"
      },
      "outputs": [],
      "source": [
        "# # NB using tf-idf\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#            0       0.96      0.97      0.97      7430\n",
        "#            1       0.55      0.48      0.51       561\n",
        "\n",
        "#     accuracy                           0.94      7991\n",
        "#    macro avg       0.75      0.72      0.74      7991\n",
        "# weighted avg       0.93      0.94      0.93      7991\n",
        "\n",
        "# # NB using word2vec\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#            0       0.98      0.85      0.91      7430\n",
        "#            1       0.29      0.82      0.43       561\n",
        "\n",
        "#     accuracy                           0.85      7991\n",
        "#    macro avg       0.64      0.83      0.67      7991\n",
        "# weighted avg       0.94      0.85      0.88      7991"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmmJzPMaqHSp"
      },
      "source": [
        "10. Visualize embeddings using [Embedding Projector](https://www.tensorflow.org/tensorboard/tensorboard_projector_plugin) in Tensorboard. \n",
        "The setup for Tensorboard can be tricky, most of the code is provided. \n",
        "\n",
        "    TensorBoard reads tensors and metadata from the logs of your tensorflow projects. \n",
        "    The path to the log directory is specified with log_dir below. \n",
        "    \n",
        "    In order to load the data into Tensorboard, we need to save a training checkpoint to that directory, along with metadata that allows for visualization of a specific layer of interest in the model.\n",
        "\n",
        "    Load the TensorBoard notebook extension and import `projector` from `tensorboard.plugins`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-Nlj-xPcDcJ"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPv_upTPcEB6"
      },
      "outputs": [],
      "source": [
        "from tensorboard.plugins import projector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6FqHvlWqHSp"
      },
      "source": [
        "11. Clear any logs from previous runs if any."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFJH2kexhsDW"
      },
      "outputs": [],
      "source": [
        "rm -rf /logs/  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ljzn8weFqHSp"
      },
      "source": [
        "12. Set up a logs directory, so Tensorboard knows where to look for data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNONqOdoeB65"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "log_dir='/logs/tweets-example/'\n",
        "if not os.path.exists(log_dir):\n",
        "    os.makedirs(log_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pYgffwFqHSp"
      },
      "source": [
        "13. Save the first `VOCAB_SIZE` most frequent words in the vocabulary as `metadata.tsv`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7ThVTUleT9o"
      },
      "outputs": [],
      "source": [
        "with open(os.path.join(log_dir, 'metadata.tsv'), \"w\") as f:\n",
        "  i = 0\n",
        "  for label in tokenizer.word_index.keys():\n",
        "    if label == 'oov':\n",
        "      continue # skip oov\n",
        "    f.write(\"{}\\n\".format(label))\n",
        "    if i > VOCAB_SIZE:\n",
        "      break\n",
        "    i += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djoU3-LcqHSp"
      },
      "source": [
        "14. Save the weights we want to analyze as a variable. Note that the first value represents any unknown word, which is not in the metadata, here we will remove this value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GoPzZpeHeZGV"
      },
      "outputs": [],
      "source": [
        "weights = tf.Variable(model.layers[0].get_weights()[0][1:]) # `embeddings` has a shape of (num_vocab, embedding_dim) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PfF91UpqHSp"
      },
      "source": [
        "15. Create a checkpoint from embedding, the filename and key are the name of the tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLC5D9PCqHSq"
      },
      "outputs": [],
      "source": [
        "checkpoint = tf.train.Checkpoint(embedding=weights)\n",
        "checkpoint.save(os.path.join(log_dir, \"embedding.ckpt\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhRQaOPUqHSq"
      },
      "source": [
        "16. Set up config."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cH4m0nY7IUFd"
      },
      "outputs": [],
      "source": [
        "config = projector.ProjectorConfig()\n",
        "embedding = config.embeddings.add()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_7mVeSHqHSq"
      },
      "source": [
        "17. The name of the tensor will be suffixed by `/.ATTRIBUTES/VARIABLE_VALUE`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LH5DxopZqHSq"
      },
      "outputs": [],
      "source": [
        "embedding.tensor_name = \"embedding/.ATTRIBUTES/VARIABLE_VALUE\"\n",
        "embedding.metadata_path = 'metadata.tsv'\n",
        "projector.visualize_embeddings(log_dir, config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fbk41Eo3qHSq"
      },
      "source": [
        "18. Verify the following files exist under the current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2Cr_8A4hRHq"
      },
      "outputs": [],
      "source": [
        "ls /logs/tweets-example/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2iMkZh8qHSq"
      },
      "source": [
        "19. Now run Tensorboard against on log data we just saved. \n",
        "\n",
        "    You may need to run this cell **twice** to see the projector correctly. \n",
        "    Use Chrome for least friction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQnjWJpSeh1e"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir /logs/tweets-example/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TC52pxQ6pFIP"
      },
      "source": [
        "The TensorBoard Projector can be a great tool for interpreting and visualzing embedding. The dashboard allows users to search for specific terms, and highlights words that are adjacent to each other in the embedding (low-dimensional) space. Try a few word in the Search box and see if the embeddings make sense. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRlfqbv5FAgr"
      },
      "source": [
        "# Task 6. Interpretation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8Z5epwHqHSr"
      },
      "source": [
        "Lastly let's try to understnad predictions by BiLSTM using a model agnostic approach -- [Local interpretable model-agnostic explanations (LIME)](https://christophm.github.io/interpretable-ml-book/lime.html)\n",
        "\n",
        "1. Import `LimeTextExplainer` from the [`lime_text`](https://lime-ml.readthedocs.io/en/latest/lime.html#module-lime.lime_text) module in package [`lime`](https://github.com/marcotcr/lime)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zve69BHRFDPW"
      },
      "outputs": [],
      "source": [
        "from lime.lime_text import LimeTextExplainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLb9MblAqHSr"
      },
      "source": [
        "2. Create an instance of `LimeTextExplainer`, call it `explanier`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awkFCv5qFEpt"
      },
      "outputs": [],
      "source": [
        "explainer = LimeTextExplainer(class_names=['no', 'yes'], random_state=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGB_kjmIqHSr"
      },
      "source": [
        "3. Method `explain_instance` expects the `classifier_fn` to be a function, we provide the function `predict_proba` as below. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fATA1nDYFNCH"
      },
      "outputs": [],
      "source": [
        "def predict_proba(arr):\n",
        "    processed = tokenizer.texts_to_sequences(arr)\n",
        "    processed = pad_sequences(processed, padding='post', maxlen=MAX_LEN)\n",
        "    pred = model.predict(processed)\n",
        "    r = []\n",
        "    for i in pred:\n",
        "        temp = i[0]\n",
        "        r.append(np.array([1-temp,temp])) \n",
        "    return np.array(r)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOOET9F0qHSr"
      },
      "source": [
        "4. Read about [`explain_instance`](https://lime-ml.readthedocs.io/en/latest/lime.html#lime.lime_text.LimeTextExplainer.explain_instance). \n",
        "\n",
        "    Create an instance named `exp` to explain the 16399th tidy tweet from the original dataset, i.e., `raw.tidy_tweet.iloc[16399]`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlACxediFQb0"
      },
      "outputs": [],
      "source": [
        "idx = 16399 \n",
        "exp = explainer.explain_instance(\n",
        "    # YOUR CODE HERE\n",
        "    num_features=6)\n",
        "exp.show_in_notebook(text=raw.tidy_tweet.iloc[idx])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ts3AF8TqHSr"
      },
      "source": [
        "5. Pick another random tweet and generate explanations for the prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZqQCxsyFSJY"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SS9n6kkVqHSr"
      },
      "source": [
        "6. Jot down your observations in explaining the model. \n",
        "\n",
        "    YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How does the Naive Bayes Classifier work?\n",
        "What is Posterior Probability?\n",
        "\n",
        "The Naive Bayes Classifier is a probabilistic classifier that uses the Bayes Theorem to make prediction. Bayes Theorem works on conditional probability, i.e. the probability that an event will happen, given another event has already occurred. \n",
        "\n",
        "The Naive Bayes classifier predicts membership probabilities for each class such as the probability that given record or data point belongs to a particular class.  In detail, it assumes that the data features are independent of each other, i.e. the occurrence of one feature does not affect the occurence of the other. Next, it calculates the likelihood function which is the probability of each feature given its class. Besides, it calculates the prior probability. Prior probability is the probability of each class occurring without taking into account the features. \n",
        "\n",
        "To make a classification for a data point based on Naive Bayes, the posterior probabilities of each class are computed. The posterior probability is the probability of a class occuring given the features of the specific data point. It is calculated based on Bayes' theorem:\n",
        "\n",
        "Posterior Probability = (Prior Probability * Likelihood Function) / Marginal Likelihood\n",
        "\n",
        ", where\n",
        "\n",
        "Marginal Likelihood = Sum of (Prior Probability * Likelihood Function) for all classes\n",
        "\n",
        "The Naive Bayes Classifier selects the class with the highest posterior probability as the predicted class for the specific data point. This algorithm is commonly used in text classification and spam filtering because it can handle a large number of features and works well even when the data is high-dimensional."
      ],
      "metadata": {
        "id": "oM0Q6qSqfD3E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the difference between stemming and lemmatization in NLP?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "In the field of Natural Language Processing i.e., NLP, Lemmatization and Stemming are Text Normalization techniques. These techniques are used to prepare words, text, and documents for further processing.\n",
        "\n",
        "The main difference between stemming and lemmatization is that stemming is a more crude and simplistic approach, while lemmatization is a more complex and accurate approach that takes into account the context and meaning of the word.\n",
        "This is why lemmatization takes more time as compared to stemming because it finds a meaningful word/representation. Stemming just needs to get a base word and therefore takes less time.\n",
        "\n",
        "Stemming has its application in Sentiment Analysis while Lemmatization has its application in Chatbots, human-answering.\n"
      ],
      "metadata": {
        "id": "X_i_XJhboA-G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is Word2Vec and how does it work?\n",
        "\n",
        "Word2Vec is a popular natural language processing (NLP) technique for learning distributed representations of words in a high-dimensional vector space. Using a particularly computationally-efficient predictive model for learning word embeddings from raw text, it allows for efficient computation of semantic similarity and the ability to perform various vector operations on words. \n",
        "It is trained using a neural network to predict context or target words. Word2Vec comes in two flavors, the Continuous Bag-of-Words (CBOW) model and the Skip-Gram model."
      ],
      "metadata": {
        "id": "I_N49Lnrr0rO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When to use GRU over LSTM?\n",
        "\n",
        "Both Gated Recurrent Units (GRUs) and Long Short-Term Memory (LSTM) are popular types of recurrent neural networks (RNNs) that are used for sequence modeling tasks, such as natural language processing (NLP) and speech recognition. GRUs and LSTMs utilize different approaches toward gating information to prevent the vanishing gradient problem. Here are the main points comparing the two:\n",
        "\n",
        "GRUs utilize less features than LSTM. This makes GRUs faster to train, less prone to overfitting and more suitable for fitting limited training data. GRUs are, thus, more computationally efficient which makes them more suitable for real-time processing applications. On the other hand, LSTM is more suitable when modeling complex long-term dependencies."
      ],
      "metadata": {
        "id": "OopdIEBUtkb9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1DXyQkTz50O"
      },
      "source": [
        "# Acknowledgement & Reference"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2EZrNZS0pFvF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnrR8TmJz8AM"
      },
      "source": [
        "- Data is adapted from [Twitter sentiment analysis](https://datahack.analyticsvidhya.com/contest/practice-problem-twitter-sentiment-analysis/#ProblemStatement)\n",
        "- [Twitter sentiment analysis](https://github.com/prateekjoshi565/twitter_sentiment_analysis/blob/master/code_sentiment_analysis.ipynb) \n",
        "- [Introduction to Word Embedding and Word2Vec](https://towardsdatascience.com/introduction-to-word-embedding-and-word2vec-652d0c2060fa)\n",
        "- [When to use GRU over LSTM?](https://datascience.stackexchange.com/questions/14581/when-to-use-gru-over-lstm)\n",
        "- Use a trained Word2Vec, Doc2Vec or FastTest embedding by `gensim` in buiding an embedding layers in Tensorflow, here's [how-to](https://github.com/RaRe-Technologies/gensim/wiki/Using-Gensim-Embeddings-with-Keras-and-Tensorflow)."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.14 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.14"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "vscode": {
      "interpreter": {
        "hash": "a665b5d41d17b532ea9890333293a1b812fa0b73c9c25c950b3cedf1bebd0438"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}